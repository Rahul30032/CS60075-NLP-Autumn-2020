{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_5_NLP (1).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e6c7991a117649d1ae308b37a16cbe84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e4f3a9cee3c8439198367970dc480fb5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_244bca804934481888e18006604ed53b","IPY_MODEL_a61f13f914ef4c14b32d11061404a06f"]}},"e4f3a9cee3c8439198367970dc480fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"244bca804934481888e18006604ed53b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9ca4f370ba24457e9c9bd2b25fb5492a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_677a7ca20f494ad58350bc05ac1c3066"}},"a61f13f914ef4c14b32d11061404a06f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_691ad53faa2e4fd7992bc16241cf6a05","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 304kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ffff04c451a14b70b903a2554038c0c6"}},"9ca4f370ba24457e9c9bd2b25fb5492a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"677a7ca20f494ad58350bc05ac1c3066":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"691ad53faa2e4fd7992bc16241cf6a05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ffff04c451a14b70b903a2554038c0c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3215013c52e4ee0bcd19c8bad2680e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1506a469759e403da1505432daf9f67f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_985c28c7214e4ceb844f1094fdcb46a3","IPY_MODEL_951dc7af38264a2f9e0827a47aa1b9db"]}},"1506a469759e403da1505432daf9f67f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"985c28c7214e4ceb844f1094fdcb46a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7494efcc80034785a118095425c58aeb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6dcebb9f46154abb913d2fb795fbc2cd"}},"951dc7af38264a2f9e0827a47aa1b9db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_29d92080ef1e4cae9013299e122aabe6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:01&lt;00:00, 238B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6225b160f82b4ff29b7b3068f6e317be"}},"7494efcc80034785a118095425c58aeb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6dcebb9f46154abb913d2fb795fbc2cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29d92080ef1e4cae9013299e122aabe6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6225b160f82b4ff29b7b3068f6e317be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f6f57f5f77349f395a34290d9f2cb6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5204c5ec17a3415e974d05f94deacd36","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_613bc3d69c614322baad53ad88a60964","IPY_MODEL_ad30e1673aa74d7784f1c93a3bf5ab77"]}},"5204c5ec17a3415e974d05f94deacd36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"613bc3d69c614322baad53ad88a60964":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_084cffd50b324beeb95b500196bd8eba","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_231a5e3038fe498cbb46c23d9b18cdab"}},"ad30e1673aa74d7784f1c93a3bf5ab77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_17e13e2d960c4c259aafd61e4868a485","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:09&lt;00:00, 48.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f680508969e14c949161b185c4803065"}},"084cffd50b324beeb95b500196bd8eba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"231a5e3038fe498cbb46c23d9b18cdab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17e13e2d960c4c259aafd61e4868a485":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f680508969e14c949161b185c4803065":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"zyJ25uz0kSaw"},"source":["\n","\n","\n","# Assignment 5 on Natural Language Processing\n","\n","## Date : 3rd Nov, 2020\n","\n","### Instructor : Prof. Sudeshna Sarkar\n","\n","### Teaching Assistants : Alapan Kuila, Aniruddha Roy, Anusha Potnuru, Uppada Vishnu"]},{"cell_type":"markdown","metadata":{"id":"Ao1nhg9RknmF"},"source":["The central idea of this assignment is to explore various language models specifically LSTM based and transformer. We will explore how the size of the model effects the sequence generated. We will see both character based and word based models.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ONM5Q4SCe9Mr"},"source":["Please submit with outputs. Submissions without predicted outputs will be penalized."]},{"cell_type":"markdown","metadata":{"id":"IXdkhxZAXnTW"},"source":["# Word Based LSTM model"]},{"cell_type":"code","metadata":{"id":"FbU5DRolXseI"},"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n","import numpy\n","import re\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d2NR3RFFYOT8"},"source":["Do basic pre processing which includes lowering etc\n","Check the dataset and apply suitable preprocessing."]},{"cell_type":"code","metadata":{"id":"iQvfF2NjXxGj"},"source":["# Load the data and preprocess data and store corpus in raw_text\n","import io\n","path = \"./corpus.txt\"\n","def preprocess(text=None, path=None):\n","  if path != None:\n","    with io.open(path, encoding=\"utf-8\") as f:\n","        text = f.read().lower()\n","  else:\n","    text = text.lower()\n","\n","  # Removing unnecessary characters\n","  text = text.replace(\"\\n\", \" \")\n","  text = text.replace(\"_\", \"\")\n","  text = text.replace(\"—\", \" \")\n","  text = text.replace(\"-\", \" \")\n","  text = text.replace(\"(\", \"\")\n","  text = text.replace(\")\", \"\")\n","  text = text.replace(\"[\", \"\")\n","  text = text.replace(\"]\", \"\")\n","  text = text.replace(\"  \", \" \") # Above replacements may cause double spaces, this is to fix that\n","\n","  char_level = text\n","#  word_level = re.sub('[\\W_]+', '', text)\n","  word_level = re.sub('[^a-z\\d\\s]', '', char_level) # Removing all special characters for word level modelling\n","  return char_level, word_level\n","\n","_,raw_text = preprocess(path=path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eug68GOecM8Z"},"source":["# Hyperparameters of the model\n","vocab_size = 2613 # choose based on statistics\n","oov_tok = '<OOV>'\n","embedding_dim = 100\n","padding_type='post'\n","trunc_type='post'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bWNBOlJ5cQym"},"source":["# tokenize sentences\n","tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n","tokenizer.fit_on_texts([raw_text])\n","word_index = tokenizer.word_index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNRJDbFcdHbO"},"source":["seq_length = 50\n","tokens = tokenizer.texts_to_sequences([raw_text])[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykfI4FrwdyJe","outputId":"74534d0f-20d0-42c2-bf11-54dd1fb5db7c","colab":{"base_uri":"https://localhost:8080/"}},"source":["dataX = []\n","dataY = []\n","\n","for i in range(0, len(tokens) - seq_length-1 , 1):\n","  seq_in = tokens[i:i + seq_length]\n","  seq_out = tokens[i + seq_length]\n","\n","  if seq_out==1: #Skip samples where target word is OOV\n","    continue\n","    \n","  dataX.append(seq_in)\n","  dataY.append(seq_out)\n"," \n","N = len(dataX)\n","print (\"Total training data size: \", N)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total training data size:  26635\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cJmGr1xId8cO"},"source":["X = numpy.array(dataX).reshape(len(dataX), len(dataX[0]), 1)\n","# one hot encode the output variable\n","y = numpy.array(dataY)\n","y = np_utils.to_categorical(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QPApRA-d9JV","outputId":"2ddfb6ba-3293-411f-a241-1da44a96e3c4","colab":{"base_uri":"https://localhost:8080/"}},"source":["# with embedding\n","model = keras.Sequential([\n","    keras.layers.Embedding(vocab_size, embedding_dim, input_length=seq_length),\n","    keras.layers.Bidirectional(keras.layers.LSTM(256)),\n","    keras.layers.Dense(vocab_size, activation='softmax')\n","])\n","# compile model\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","# model summary\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 50, 100)           261300    \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 512)               731136    \n","_________________________________________________________________\n","dense (Dense)                (None, 2613)              1340469   \n","=================================================================\n","Total params: 2,332,905\n","Trainable params: 2,332,905\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"14ClAAYpeCVO","outputId":"4899131c-c440-4427-c327-5e2f3aa10949","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Use validation split of 0.2 while training\n","model.fit(X, y, epochs=25, batch_size=32, verbose=1, validation_split=0.2) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","666/666 [==============================] - 11s 16ms/step - loss: 6.1616 - accuracy: 0.0590 - val_loss: 6.1098 - val_accuracy: 0.0897\n","Epoch 2/25\n","666/666 [==============================] - 10s 15ms/step - loss: 5.6493 - accuracy: 0.0737 - val_loss: 6.0035 - val_accuracy: 0.1059\n","Epoch 3/25\n","666/666 [==============================] - 10s 15ms/step - loss: 5.2299 - accuracy: 0.1016 - val_loss: 5.9452 - val_accuracy: 0.1158\n","Epoch 4/25\n","666/666 [==============================] - 10s 15ms/step - loss: 4.7256 - accuracy: 0.1328 - val_loss: 6.0125 - val_accuracy: 0.1149\n","Epoch 5/25\n","666/666 [==============================] - 10s 15ms/step - loss: 4.1336 - accuracy: 0.1737 - val_loss: 6.1914 - val_accuracy: 0.1119\n","Epoch 6/25\n","666/666 [==============================] - 10s 15ms/step - loss: 3.4290 - accuracy: 0.2561 - val_loss: 6.4662 - val_accuracy: 0.0982\n","Epoch 7/25\n","666/666 [==============================] - 10s 15ms/step - loss: 2.7121 - accuracy: 0.3929 - val_loss: 6.7801 - val_accuracy: 0.0920\n","Epoch 8/25\n","666/666 [==============================] - 10s 15ms/step - loss: 2.1003 - accuracy: 0.5173 - val_loss: 7.0197 - val_accuracy: 0.0895\n","Epoch 9/25\n","666/666 [==============================] - 10s 15ms/step - loss: 1.6072 - accuracy: 0.6342 - val_loss: 7.2526 - val_accuracy: 0.0877\n","Epoch 10/25\n","666/666 [==============================] - 10s 15ms/step - loss: 1.2011 - accuracy: 0.7366 - val_loss: 7.4748 - val_accuracy: 0.0849\n","Epoch 11/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.8652 - accuracy: 0.8252 - val_loss: 7.7491 - val_accuracy: 0.0847\n","Epoch 12/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.5969 - accuracy: 0.8972 - val_loss: 7.9733 - val_accuracy: 0.0850\n","Epoch 13/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.3843 - accuracy: 0.9516 - val_loss: 8.2392 - val_accuracy: 0.0860\n","Epoch 14/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.2342 - accuracy: 0.9808 - val_loss: 8.4323 - val_accuracy: 0.0850\n","Epoch 15/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.1349 - accuracy: 0.9944 - val_loss: 8.7547 - val_accuracy: 0.0856\n","Epoch 16/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.0759 - accuracy: 0.9990 - val_loss: 8.9240 - val_accuracy: 0.0828\n","Epoch 17/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.0426 - accuracy: 0.9997 - val_loss: 9.1101 - val_accuracy: 0.0805\n","Epoch 18/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.0288 - accuracy: 0.9997 - val_loss: 9.2879 - val_accuracy: 0.0828\n","Epoch 19/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.0236 - accuracy: 0.9997 - val_loss: 9.4252 - val_accuracy: 0.0817\n","Epoch 20/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.3595 - accuracy: 0.9091 - val_loss: 9.1544 - val_accuracy: 0.0758\n","Epoch 21/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.1582 - accuracy: 0.9755 - val_loss: 9.4093 - val_accuracy: 0.0787\n","Epoch 22/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.0269 - accuracy: 0.9999 - val_loss: 9.5602 - val_accuracy: 0.0820\n","Epoch 23/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 9.6836 - val_accuracy: 0.0822\n","Epoch 24/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 9.7828 - val_accuracy: 0.0832\n","Epoch 25/25\n","666/666 [==============================] - 10s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 9.8906 - val_accuracy: 0.0820\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fddf11eb780>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"mg9WSEwYeMAH"},"source":["reverse_word_map = {value: key for key, value in tokenizer.word_index.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_mhL0J0eQku"},"source":["# Complete the code to return next n words greedily\n","def next_tokens(input_str, n): \n","\tprint (\"Seed: \\n\", input_str)\n","\tinput_string = input_str\n","\tfinal_string = \"\"\n","\tfor i in range(n):\n","\t\tfinal_string += \" \"\n","\t\tnew_X = np.asarray(tokenizer.texts_to_sequences([input_string])[0]).reshape(1, 50, 1)\n","\t\tprediction = model.predict(new_X, verbose=0)\n","\t\t# get next word index. Use reverse_word_map to get the word\n","\t\tpred_word = reverse_word_map[np.argmax(prediction)]\n","\t\tinput_string = input_string + \" \" + pred_word\n","\t\tfinal_string += pred_word\n","\t\tinput_string = ' '.join(input_string.split(\" \")[1:])\n","\treturn final_string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gZ_NTQezeWYO","outputId":"7767bfd9-f865-4aef-c445-b4b49e7c44b6","colab":{"base_uri":"https://localhost:8080/"}},"source":["# pick a random seed\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","input_str = ' '.join([reverse_word_map[value] for value in pattern])\n","\n","print(next_tokens(input_str, 25))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Seed: \n"," twice half hoping that they would call after her the last time she saw them they were trying to put the dormouse into the teapot at any rate ill never go there again said alice as she picked her way through the wood its the stupidest tea party i ever\n"," was at in all my life just as she said this she noticed that one of the trees had a door leading right into it\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u-x8W-OSVgNi","outputId":"7c2e8e9f-a0bf-4060-b88a-ef618666aeee","colab":{"base_uri":"https://localhost:8080/"}},"source":["input_str = \"The boy laughed at the fright he had caused. This time, the villagers left angrily. The third day, as the boy went up\\\n"," the small hill, he suddenly saw a wolf attacking his sheep. He cried as hard as he could, “Wolf! Wolf! Wolf!”, but not \\\n"," a single villager came to help him. The villagers thought that he was trying to fool them again and did not come to rescue \\\n"," him or his sheep.\"\n","\n","# Use first 50 tokens from given input_str as input.(Use tokenizer to split to take first 50)\n","_,prep_input = preprocess(text=input_str)\n","input = ' '.join(prep_input.split(\" \")[:50])\n","print(next_tokens(input , 10))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Seed: \n"," the boy laughed at the fright he had caused this time the villagers left angrily the third day as the boy went up the small hill he suddenly saw a wolf attacking his sheep he cried as hard as he could wolf wolf wolf but not a single villager came\n"," in the executioner thought it to her with a game\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B5_R5Tngo3_D"},"source":["# Character based LSTM Model 1"]},{"cell_type":"code","metadata":{"id":"2zZaHsejo57p"},"source":["# User the preprocess data and create raw_text\n","raw_text,_ = preprocess(path=path)\n","# create mapping of unique characters to integers\n","chars = sorted(list(set(raw_text)))\n","\n","char_to_int = {c: i for i, c in enumerate(chars)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lkVVDbump0Wg","outputId":"e6c90d07-ab8e-46c1-c341-ef4e8a77bf45","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Print the total characters and character vacob size\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","\n","print(n_chars, n_vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["141898 38\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2aVserymqE1b","outputId":"7c886654-9223-4296-e122-aecb20a9ebce","colab":{"base_uri":"https://localhost:8080/"}},"source":["'''\n","Prepare dataset where the input is sequence of 100 characters and target is next character.\n","'''\n","char_nums = [char_to_int[char] for char in raw_text]\n","seq_length = 100\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","  seq_in = char_nums[i:i + seq_length]\n","  seq_out = char_nums[i + seq_length]\n","\n","  dataX.append(seq_in)\n","  dataY.append(seq_out)\n","\n","n_patterns = len(dataX)\n","print (\"Total Patterns: \", n_patterns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total Patterns:  141798\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ic4yf4hNqc7T"},"source":["# reshape X to be [samples, time steps, features]\n","X = numpy.array(dataX).reshape(len(dataX), len(dataX[0]), 1)\n","# one hot encode the output variable\n","dataY = numpy.array(dataY)\n","y = np_utils.to_categorical(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvawnjFVqhMi"},"source":["embedding_dim = 100\n","max_length = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ek5DqNeTqkAZ","outputId":"73a20b7b-23db-4264-d8d4-aaf9c4c26c61","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = Sequential()\n","model.add(keras.layers.Embedding(n_vocab, embedding_dim, input_length=max_length))\n","model.add(LSTM(256))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 100, 100)          3800      \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 256)               365568    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 38)                9766      \n","=================================================================\n","Total params: 379,134\n","Trainable params: 379,134\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gFoStJIOqpM6","outputId":"3b44f45e-6be5-450a-eb89-c9640bac4dd5","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.fit(X, y, epochs=25, batch_size=64)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","2216/2216 [==============================] - 28s 13ms/step - loss: 2.0273\n","Epoch 2/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.5616\n","Epoch 3/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.3967\n","Epoch 4/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.2994\n","Epoch 5/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.2305\n","Epoch 6/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.1738\n","Epoch 7/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.1295\n","Epoch 8/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.0928\n","Epoch 9/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.0574\n","Epoch 10/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.0272\n","Epoch 11/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 1.0004\n","Epoch 12/25\n","2216/2216 [==============================] - 28s 13ms/step - loss: 0.9773\n","Epoch 13/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.9553\n","Epoch 14/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.9354\n","Epoch 15/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.9182\n","Epoch 16/25\n","2216/2216 [==============================] - 27s 12ms/step - loss: 0.9054\n","Epoch 17/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.8903\n","Epoch 18/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.8798\n","Epoch 19/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.8707\n","Epoch 20/25\n","2216/2216 [==============================] - 27s 12ms/step - loss: 0.8621\n","Epoch 21/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.8532\n","Epoch 22/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.8472\n","Epoch 23/25\n","2216/2216 [==============================] - 28s 13ms/step - loss: 0.8422\n","Epoch 24/25\n","2216/2216 [==============================] - 28s 13ms/step - loss: 0.8346\n","Epoch 25/25\n","2216/2216 [==============================] - 28s 12ms/step - loss: 0.8346\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fddf09396d8>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"ekXYhzeUrGaq"},"source":["#implement mapping of integer to character\n","int_to_char = {i: c for i, c in enumerate(chars)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OixPrw6vq15j"},"source":["'''\n","Complete code below to get the generated string using the model.\n","'''\n","def predict_next_100_chars(pattern,x):\n","\tinput_pattern = pattern\n","\tfinal_string = \"\"\n","\tfor i in range(x):\n","\t\tnew_X = np.array([(char_to_int[char]) for char in input_pattern])\n","\t\tnew_X = new_X.reshape((1, len(pattern), 1))\n","\t\tprediction = model.predict(new_X, verbose=0)\n","#\t\tpred_sampled = np.random.choice(len(prediction[0]), p=prediction[0])\n","\t\tpred_sampled = np.argmax(prediction[0])\n","\t\tpred_char = int_to_char[pred_sampled]\n","\t\tfinal_string += pred_char\n","\t\tinput_pattern += pred_char\n","\t\tinput_pattern = input_pattern[1:]\n","\treturn final_string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHH_I5QiUxnY","outputId":"1404367c-2166-46a6-b470-d199060476b1","colab":{"base_uri":"https://localhost:8080/"}},"source":["# pick a random seed\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","input_str = ''.join([int_to_char[value] for value in pattern])\n","print(\"Seed:\\n\", input_str)\n","\n","print(predict_next_100_chars(input_str,200))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Seed:\n"," , “i feared it might injure the brain; but, now that i’m perfectly sure i have none, why, i do it ag\n","ain the door of the end of the world ear was some of the english,” the gryphon asked the mock turtle as she went on, “you were never marked it was a little way of meaning in a treecle, for the things \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iutpuJAgrgU8","outputId":"906bd167-ecdc-4cb4-ad3c-8264957490d7","colab":{"base_uri":"https://localhost:8080/"}},"source":["input_str = \"The boy laughed at the fright he had caused. This time, the villagers left angrily. The third day, as the boy went up\\\n"," the small hill, he suddenly saw a wolf attacking his sheep. He cried as hard as he could, “Wolf! Wolf! Wolf!”, but not \\\n"," a single villager came to help him. The villagers thought that he was trying to fool them again and did not come to rescue \\\n"," him or his sheep.\"\n","\n"," # Use first 100 characeters from given input_str as input and generate next 200 characters.\n","input_str = input_str[:100].lower()\n","print(\"Seed: \", input_str)\n","print(predict_next_100_chars(input_str,200))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Seed:  the boy laughed at the fright he had caused. this time, the villagers left angrily. the third day, a\n","nd she was silence to herself herself to alice who had to such a thing it as she was so much at the court, and then alice could not stand on the table, but then she was silently that she was quite ple\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n8shbcukr0tJ"},"source":["## Character based LSTM Model 2\n"]},{"cell_type":"code","metadata":{"id":"BWBPCrTdr46U"},"source":["model1 = Sequential()\n","model1.add(keras.layers.Embedding(n_vocab, embedding_dim, input_length=max_length))\n","model1.add(LSTM(256, input_shape=(X.shape[1], embedding_dim),return_sequences=True))\n","model1.add(Dropout(0.2))\n","model1.add(LSTM(256))\n","model1.add(Dropout(0.2))\n","model1.add(Dense(y.shape[1], activation='softmax'))\n","model1.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZxrtjFIr63L","outputId":"5588f3cb-e6f5-48ec-abbf-276161d6a2be","colab":{"base_uri":"https://localhost:8080/"}},"source":["model1.fit(X, y, epochs=20, batch_size=64)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 2.0568\n","Epoch 2/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.5370\n","Epoch 3/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.3622\n","Epoch 4/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.2661\n","Epoch 5/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.1975\n","Epoch 6/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.1454\n","Epoch 7/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.1008\n","Epoch 8/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.0642\n","Epoch 9/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.0339\n","Epoch 10/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 1.0037\n","Epoch 11/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.9814\n","Epoch 12/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.9591\n","Epoch 13/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.9384\n","Epoch 14/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.9203\n","Epoch 15/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.9032\n","Epoch 16/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.8923\n","Epoch 17/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.8792\n","Epoch 18/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.8692\n","Epoch 19/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.8595\n","Epoch 20/20\n","2216/2216 [==============================] - 52s 23ms/step - loss: 0.8506\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fdd5924af60>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"L6RTfHN6r8wh"},"source":["# Generate the sequence similar to above methods\n","\n","'''\n","Complete code below to get the generated string using the model.\n","'''\n","\n","def predict_next_100_chars(pattern,x):\n","\tinput_pattern = pattern\n","\tfinal_string = \"\"\n","\tfor i in range(x):\n","\t\tnew_X = np.array([(char_to_int[char]) for char in input_pattern])\n","\t\tnew_X = new_X.reshape((1, len(pattern), 1))\n","\t\tprediction = model1.predict(new_X, verbose=0)\n","#\t\tpred_sampled = np.random.choice(len(prediction[0]), p=prediction[0])\n","\t\tpred_sampled = np.argmax(prediction[0])\n","\t\tpred_char = int_to_char[pred_sampled]\n","\t\tfinal_string += pred_char\n","\t\tinput_pattern += pred_char\n","\t\tinput_pattern = input_pattern[1:]\n","\treturn final_string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5CKJXZ4tYmL0","outputId":"f965a6ef-d8b0-463a-8fe8-0bebf10ece85","colab":{"base_uri":"https://localhost:8080/"}},"source":["# pick a random seed\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","input_str = ''.join([int_to_char[value] for value in pattern])\n","\n","print(predict_next_100_chars(input_str,200))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" words were three of the words “drink me the rest of the sea. “i don’t know what they were orderand, i wonder what i say that is to grow about it, you know, with the dormouse,” said the king. “nothing\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YyRCfLe5YmL7","outputId":"2ea5429b-5127-471a-ef01-be6eeb1c7eab","colab":{"base_uri":"https://localhost:8080/"}},"source":["input_str = \"The boy laughed at the fright he had caused. This time, the villagers left angrily. The third day, as the boy went up\\\n"," the small hill, he suddenly saw a wolf attacking his sheep. He cried as hard as he could, “Wolf! Wolf! Wolf!”, but not \\\n"," a single villager came to help him. The villagers thought that he was trying to fool them again and did not come to rescue \\\n"," him or his sheep.\"\n","\n"," # Use first 100 characeters from given input_str as input and generate next 200 characters.\n","input_str = input_str[:100].lower()\n"," \n","print(predict_next_100_chars(input_str,200))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nd she went on, “i wonder what i say that is to grow about it, you know, with the dormouse,” said the king. “nothing would not, could not, could not, could not, could not, could not, could not, could \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XPrjxjoNsaQC"},"source":["# Questions"]},{"cell_type":"markdown","metadata":{"id":"kW5_IlBeZAPq"},"source":["**Question:** What are your observations based on the model(all) outputs on train data(in domain) vs unseen data(out of domain) ?"]},{"cell_type":"markdown","metadata":{"id":"YryzP1upZv5h"},"source":["**Answer:** The correlation between seed text and generated text is much more on the train data than on the unseen data. This is most starkly observed in the word level model.\n","The characters from the input text such as alice, caterpillar, hatter, etc show up in the generated text regardless of the seed."]},{"cell_type":"markdown","metadata":{"id":"aBzCD0I0Z3uP"},"source":["**Question:** What did you observe in the outputs of char LSTM model1 vs char LSTM model2 ?"]},{"cell_type":"markdown","metadata":{"id":"PUHxHmXZaNdn"},"source":["**Answer:** Seen over multiple text generations and experimentation with longer predictions as well, the following things are observed:\n","* Due to the second LSTM layer, the second model captures deeper representations and longer range dependencies better than the first model.\n","* Both models start looping when sampling is done greedily (as opposed to the more optimal Beam Search) but the second model has longer loops, indicating a deeper understanding of the corpus it is trained on."]},{"cell_type":"markdown","metadata":{"id":"rShXR9sYsc4D"},"source":["# Bonus (Not to be graded)"]},{"cell_type":"markdown","metadata":{"id":"j2N-l6VSshhC"},"source":["## Transformer based language model (Bert)\n","You can run the below cells to predict the next word using pretrained BERT model. "]},{"cell_type":"code","metadata":{"id":"67c13Yx9sgiW","outputId":"2ee4521c-a681-47b7-a782-0160c26a5a65","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 28.5MB/s \n","\u001b[?25hCollecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 42.9MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 47.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=95301894fcbcc09b8dad43504e9729ca76001a21e8360893555ad3258c86a23f\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5gF2nncdsqcx"},"source":["import os\n","import torch\n","import string\n","from transformers import BertTokenizer, BertForMaskedLM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tppcQN298Qs"},"source":["def load_model(model_name):\n","  try:\n","    if model_name.lower() == \"bert\":\n","      bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","      bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased').eval()\n","      return bert_tokenizer,bert_model\n","  except Exception as e:\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOcQKOGG-H8F"},"source":["def decode(tokenizer, pred_idx, top_clean):\n","  ignore_tokens = string.punctuation + '[PAD]'\n","  tokens = []\n","  for w in pred_idx:\n","    token = ''.join(tokenizer.decode(w).split())\n","    if token not in ignore_tokens:\n","      tokens.append(token.replace('##', ''))\n","  return '\\n'.join(tokens[:top_clean])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQkjSmGv-TxO"},"source":["def encode(tokenizer, text_sentence, add_special_tokens=True):\n","  text_sentence = text_sentence.replace('<mask>', tokenizer.mask_token)\n","  # if <mask> is the last token, append a \".\" so that models dont predict punctuation.\n","  if tokenizer.mask_token == text_sentence.split()[-1]:\n","    text_sentence += ' .'\n","  input_ids = torch.tensor([tokenizer.encode(text_sentence, add_special_tokens=add_special_tokens)])\n","  mask_idx = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n","  return input_ids, mask_idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fFWOHB5n-ZQh"},"source":["def get_all_predictions(text_sentence, top_clean=5):\n","  input_ids, mask_idx = encode(bert_tokenizer, text_sentence)\n","  with torch.no_grad():\n","    predict = bert_model(input_ids)[0]\n","    print(predict.shape)\n","    \n","    bert = decode(bert_tokenizer, predict[0, mask_idx, :].topk(top_k).indices.tolist(), top_clean)\n","  return {'bert': bert}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lQHVc0l-igk"},"source":["def get_prediction_eos(input_text):\n","  try:\n","    input_text += ' <mask>'\n","    res = get_all_predictions(input_text, top_clean=int(top_k))\n","    return res\n","  except Exception as error:\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQZ-swMD9lyU","outputId":"9c9d1517-9f2e-47b9-81c4-1180e3e85e63","colab":{"base_uri":"https://localhost:8080/","height":303,"referenced_widgets":["e6c7991a117649d1ae308b37a16cbe84","e4f3a9cee3c8439198367970dc480fb5","244bca804934481888e18006604ed53b","a61f13f914ef4c14b32d11061404a06f","9ca4f370ba24457e9c9bd2b25fb5492a","677a7ca20f494ad58350bc05ac1c3066","691ad53faa2e4fd7992bc16241cf6a05","ffff04c451a14b70b903a2554038c0c6","d3215013c52e4ee0bcd19c8bad2680e1","1506a469759e403da1505432daf9f67f","985c28c7214e4ceb844f1094fdcb46a3","951dc7af38264a2f9e0827a47aa1b9db","7494efcc80034785a118095425c58aeb","6dcebb9f46154abb913d2fb795fbc2cd","29d92080ef1e4cae9013299e122aabe6","6225b160f82b4ff29b7b3068f6e317be","7f6f57f5f77349f395a34290d9f2cb6c","5204c5ec17a3415e974d05f94deacd36","613bc3d69c614322baad53ad88a60964","ad30e1673aa74d7784f1c93a3bf5ab77","084cffd50b324beeb95b500196bd8eba","231a5e3038fe498cbb46c23d9b18cdab","17e13e2d960c4c259aafd61e4868a485","f680508969e14c949161b185c4803065"]}},"source":["# Below code predicts the next top_k words. You can modify this to get next n words using top_k=1 and greedy decoding it. \n","top_k= 3\n","print('Predict next ', top_k, ' words')\n","model_name = 'BERT'\n","bert_tokenizer, bert_model  = load_model(model_name) \n","input_text = \"The boy\" ### GIVE YOUR INPUT STRING HERE\n","res = get_prediction_eos(input_text)\n","answer = []\n","print(res['bert'].split(\"\\n\"))\n","for i in res['bert'].split(\"\\n\"):\n","  answer.append(i)\n","  answer_as_string = \"    \".join(answer)\n","\n","print(answer_as_string)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predict next  3  words\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6c7991a117649d1ae308b37a16cbe84","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3215013c52e4ee0bcd19c8bad2680e1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f6f57f5f77349f395a34290d9f2cb6c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([1, 6, 30522])\n","['asked', 'nodded', 'said']\n","asked    nodded    said\n"],"name":"stdout"}]}]}